<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>reliability on Takahiro ONOSHIMA&#39;s website</title>
    <link>https://onoshima.github.io/tags/reliability/</link>
    <description>Recent content in reliability on Takahiro ONOSHIMA&#39;s website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Takahiro ONOSHIMA</copyright>
    <lastBuildDate>Mon, 07 Mar 2022 14:47:10 +0900</lastBuildDate><atom:link href="https://onoshima.github.io/tags/reliability/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>南風原(2002)の読書メモ</title>
      <link>https://onoshima.github.io/posts/haebara2002/</link>
      <pubDate>Mon, 07 Mar 2022 14:47:10 +0900</pubDate>
      
      <guid>https://onoshima.github.io/posts/haebara2002/</guid>
      <description>以下の論文を読んだメモ。心理学研究における測定誤差の論文の関連で読み直した。
 南風原朝和 (2002). モデル適合度の目標適合度. 行動計量学, 29(2), 160–166. https://doi.org/10.2333/jbhmk.29.160
 論文の概要 同じ号の狩野論文に対するコメント論文。尺度構成において，一つの構成概念あたりの観測変数の数を多くする立場（従来の尺度構成の立場）と数を抑える立場（SEMを適用する研究に見られるもの）を対比させた上で，観測変数の数を減らすことの是非を論じている。従来の希薄化の修正は「回答の際の気の迷いや読み違えなどの瞬間的な揺れ」（論文中ではタイプ2の要因による誤差）によって生じる誤差変動を除去するものである一方で，SEMにおける希薄化の修正はそれに加えて「項目プールから尺度項目として選ばれる項目の違い」（論文中ではタイプ3の要因による誤差）も合わせて誤差要因に加えて除去しており，問題設定自体を変更していると論じている。観測変数の数を減らすことの危険性については，一般化可能性が低下する可能性があること，内容的妥当性が低下する可能性があることを指摘して，モデルの適合度の振り回される危険性を論じている。
引用や感想など SEMの適合度による判断がp値の利用と同じで2値判断を求めがちな研究者の便利な道具になっているという指摘（p.165）はまさにその通りだと思った。似たようなことは信頼性係数についての調べ物をした際にも思ったことで（「信頼性係数の目安の出どころ」），あれも「十分な内的整合性を示した」と言えれば良しみたいなところがあると思う。
希薄化の修正公式について「ルーチン的に適用され，修正後の値が相関係数のより良い推定値として報告されることはなかった（p.161）」と書いており，その理由として「測定誤差」「真の得点」「信頼性」 が持つ多義性が挙げられている。たしかに，何を真の得点としてみなすのか，どのタイプの測定誤差による誤差変動を除去したいかが明確でない状態でルーチン的に修正公式を適用するのは問題があるだろう。
また，$\alpha$係数について「尺度に含まれる項目の性質によっては，かなり低い下限値を与えることがあり，coefficient of precisionの推定値としてルーチン的に利用することはできない(p.163)」と述べており，これもまたそうなのだろう。
ここで著者は「ルーチン的」には使用できないと述べており，非ルーチン的（?）に修正公式を使うことができる可能性については言及していない。$\alpha$係数はRaykov &amp;amp; Marcoulides (2019)が論じているように，尺度の1次元性の仮定が満たされていないのであれば，$\tau$等価の仮定が満たされていなくてもひどい過小推定をしないことが知られているので，$\alpha$が過小推定しないかのチェックを行ったり（仮定の緩い$\omega$を用いたり）して，尺度の性質について吟味した上で非ルーチン的に修正公式を使うのはアリだと思うが，使用する人はあまり（というよりほとんど？）見ない。測定誤差による希薄化を無視することによるリスクと希薄化の修正に過大推定のリスクではどちらが大きいのだろうか。また，こうした議論はどの程度なされているのか。
ちなみに，coefficient of precisionに日本語訳をあてているものがないか手元の書籍をいくつか見てみたが，そもそもこの語自体が登場する日本語文献がなかった。あたった文献が悪いのかもしれない。
一応Lord &amp;amp; Novick (1968)ではどう説明されているかも確認しておく。初登場の記述は以下のようなもの(p.134)。
 The correlation between truly parallel measurements taken in such a way that the person&amp;rsquo;s true score does not change between them is often called the coefficient of precision. As a reliability coeffi cient, we may write it as $$ \rho^2 _{XT} = \rho _{XX ^{&#39;} } = \sigma ^2 _{T} /\sigma ^2 _{X} = 1 - ( \sigma^2 _{E} / \sigma^2 _{X}).</description>
    </item>
    
    <item>
      <title>心理学研究における測定誤差</title>
      <link>https://onoshima.github.io/posts/schmidthunter1996/</link>
      <pubDate>Mon, 28 Feb 2022 10:30:39 +0900</pubDate>
      
      <guid>https://onoshima.github.io/posts/schmidthunter1996/</guid>
      <description>以下の論文を読んだ際のメモ。
 Schmidt, F. L., &amp;amp; Hunter, J. E. (1996). Measurement error in psychological research: Lessons from 26 research scenarios. Psychological Methods, 1(2), 199–223. https://doi.org/10.1037/1082-989X.1.2.199
 論文の概要 心理学の研究における測定誤差の問題に対してどう対処するかを論じたもの。アブストラクトにも書いてあるように，抽象的な測定理論を提示しても多くの研究者の研究実践を改善するには不十分だろうということで，具体的な研究の文脈を提示し，それぞれにおける測定誤差の誤った対処と正しい対処のあり方を議論している。提示される26個の架空の（といってもおそらく今まで出会った著者らが研究を組み合わせたものかな？）研究の例は，組織・産業心理学やパーソナリティ心理学や社会心理学などで尺度を用いた研究が多いが，実験における例なども出てくる。最初の9例が希薄化の修正をしなかったことによって謝った結論を導いてしまうことについて，続く13例が修正に用いる信頼性係数を間違うことによって引き起こされる問題について，残りの4例がより複雑なケースが論じられる。
古い論文といえば古い論文なのでこの後の議論がどう進んでいるかを追う必要があると思うが，希薄化の修正について考えるときの重要文献の一つだと思う。
引用や感想など  [E]ven in articles in which reliabilities are reported, the majority of studies do not use those reliabilities to correct findings for the distortion produced by error of measurement (p.199).
 この指摘はとても正しくて信頼性は報告されたらそれで終わりでその後の活用がなされていないのではないかということは感じる。この問題は岡田 (2015)がα係数を信頼性についての「「みそぎ」のための便利な道具（p.80）」と表現していることと同種のものだと思う。
論文のいたるところ（特に後半の研究例の箇所）で，測定に際して生じている誤差の性質（random, specific, transientなものか）についての議論と，それぞれの信頼性係数がどのような誤差を考慮しているかの議論がなされていて大変勉強になる。測定の対象とするものによってによって生じやすい誤差と生じづらい誤差を把握することは信頼性の選択に必要なことだろうと思う。以下の引用では，信頼性の解釈が測定理論のみからは決めることができない点が述べられている（ここら辺の話は帰無仮説有意性検定における危険率とか効果量の実質的な解釈の話と同じことである）。
 This scenario [シナリオ17] illustrates the important fact that substantive research findings and cumulative knowledge can modify the interpretation of reliability estimates.</description>
    </item>
    
    <item>
      <title>EFAから計算したωとCFAから計算したω</title>
      <link>https://onoshima.github.io/posts/omega_efacfa/</link>
      <pubDate>Wed, 16 Sep 2020 15:13:32 +0900</pubDate>
      
      <guid>https://onoshima.github.io/posts/omega_efacfa/</guid>
      <description>2つのω係数について 信頼性係数の1つであるω係数は$\omega_h$と$\omega_t$があって，それぞれ
$$ \omega_h = \frac{{\bf 1^{\prime} c c^{\prime} 1}}{{\rm Var}(X)} \\ \omega_t = \frac{{\bf 1^{\prime} c c^{\prime} 1}+{\bf 1^{\prime} A A^{\prime} 1}}{{\rm Var}(X)} $$
として表される。${\bf c}$は一般因子の因子負荷量ベクトルで，${\bf A}$は群因子の因子負荷量行列である。
Revelle &amp;amp; Condon（2019）によると，これらの推定値を得る方法は，（1）EFAで高次因子モデルの因子負荷量を得てその結果にScmidt-Leiman変換をかける方法と，（2）CFAで直接的に双因子モデルを指定して推定値を得る方法がある。ここでは，Rで実際にその2つをやってみてどのような違いがあるかを検討する。
使うデータはPsychパッケージに入ってるThurstoneというデータ（相関行列）。9つのテストのデータで，3つの因子（1）Verbal Comprehension,（2）Word Fluency, （3）Reasoningにまとまるようである。サンプルサイズは213らしい。
https://www.personality-project.org/r/html/bifactor.html
探索的因子分析による方法 まずは，探索的因子分析でやってみる。psych所収のomega関数を使う。とても簡単。
library(lavaan) library(psych) library(knitr) data(&amp;#34;Thurstone&amp;#34;) res_efa &amp;lt;- omega(Thurstone) kable(round(res_efa$schmid$sl,3))     g F1* F2* F3* h2 u2 p2     Sentences 0.709 0.560 -0.022 0.030 0.817 0.183 0.615   Vocabulary 0.</description>
    </item>
    
    <item>
      <title>信頼性係数の目安の出どころ</title>
      <link>https://onoshima.github.io/posts/nunnally/</link>
      <pubDate>Mon, 17 Feb 2020 20:43:28 +0900</pubDate>
      
      <guid>https://onoshima.github.io/posts/nunnally/</guid>
      <description>尺度が開発される際には信頼性と妥当性についての検討が必要とされます。信頼性の指標としてはクロンバックのαが報告されることが多いのですが，巷でαの値が0.8以上あると望ましいとかなんとか言われていたりします。
例えば次のサイトではこんな風に書かれています。
 α係数の目安は0.80以上です。0.90を超えれば、かなりの信頼性と言えます。
 http://www.u-gakugei.ac.jp/~kishilab/validity-reliability.htm
また別のサイトではこんな風に書かれています。
 通常、アルファ係数が0.8以上であれば一貫性があると見なされます。
 https://bellcurve.jp/statistics/blog/12206.html
ところで，この0.8だの0.9だのの出どころについて調べてみると，英語で書かれたもののいくつかはNunnally(1978)というものを引用しています。これは次の本みたいです。
https://www.amazon.co.jp/Psychometric-Theory-McGraw-Hill-Psychology-Nunnally/dp/0070474656
では，そこには何が書いてあるのかと図書館でみてみますと以下のような記述でした。長いけど引用しておきます。
 What a satisfactory level of reliability is depends on how a measure is being used. In the early stages of research on predictor tests or hypotesized measures of a construct, one saves time and energy by working with instruments that have ony modest reliability, for which purpose reliabilities of .70 or higher will suffice. If significant correlations are found, corrections for attenuation will estimate how much the correlations will increase when reliabilities of measures are increased.</description>
    </item>
    
    <item>
      <title>相関係数行列からクロンバックのαを求める</title>
      <link>https://onoshima.github.io/posts/cronbach/</link>
      <pubDate>Fri, 27 Dec 2019 21:37:22 +0900</pubDate>
      
      <guid>https://onoshima.github.io/posts/cronbach/</guid>
      <description>尺度の作成論文などでは信頼性係数が報告される。信頼性係数には様々な種類があるが, その中でもっともよく使われるのがクロンバックのαである。クロンバックのαは次の計算式で求められる。
$$ a = \frac{n}{n-1} \left( 1- \frac{\Sigma^n _{i=1}Var(X_i)}{Var(X)}\right) \tag{1} $$
ここで, $n$は項目数, $X_i$は$i$番目の項目の得点である。$X$はテストの合計得点である。
Rでクロンバックのαの求めるには Rでクロンバックのαを求めるためには複数のやり方がある。
http://www.okadajp.org/RWiki/?%CE%B1%E4%BF%82%E6%95%B0%EF%BC%8C%E4%BF%A1%E9%A0%BC%E6%80%A7%E4%BF%82%E6%95%B0%E3%81%AE%E7%AE%97%E5%87%BA
とりあえずここではpsychパッケージに含まれるalpha()関数を使ってみることにする。データは同じパッケージに含まれるbfiを用いる。このデータはビッグファイブ理論が想定する因子を測定する質問紙で1因子につき5項目合計25項目からなる。サンプルサイズは2800である。今回は最初の10項目だけ使う。
データの中身はこんな感じ。6件法である。
さて, このデータに対してクロンバックのαを求めるにはalpha()関数を用いるのだが, データが逆転項目を含んでいるのでそれを処理しなければいけない。6件法なので6から項目を引くと出てくる。ここではのちの話の都合で欠損を含むデータを除外している。
# 逆転項目の処理して必要な項目だけ取り出す new &amp;lt;- dat %&amp;gt;% mutate(A1=6-A1, C4=6-C4, C5=6-C5) %&amp;gt;% select(1:10) %&amp;gt;% filter(!is.na(A1), !is.na(A2), !is.na(A3), !is.na(A4), !is.na(A5), !is.na(C1), !is.na(C2), !is.na(C3), !is.na(C4), !is.na(C5)) 逆転項目の処理が済んだところで, alpha()関数を使ってみる。
# クロンバックαを計算 res &amp;lt;- psych::alpha(new) αの値が出てくるだけでなくて, 各項目をなくした際にαがどのように変化するかの値も出てくる。これらは尺度作成の際には役に立つだろう。
相関係数からクロンバックのαを求める ところで岡田（2015）によれば, クロンバックのαは相関係数行列から求めることもできるようである。
https://www.jstage.jst.go.jp/article/arepj/54/0/54_71/_article/-char/ja/
相関係数行列からクロンバックのαは次の式で求められる。
$$ a = \frac{n\bar{r}}{1+(n-1) \bar{r}} \tag{2} $$
ここでnは項目数で, $\bar{r}$は項目間の相関係数の平均である。さきほどのデータを用いて, 同様の結果が得られるが試してみる。相関係数行列を求めて, 上記の式に当てはめてみる。</description>
    </item>
    
  </channel>
</rss>
